# -*- coding: utf-8 -*-
"""Pycaret para Séries Temporais.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QpQfX-twFeXZU4rv5MjjDh7YKNl6xj_c

# Previsão de séries temporais com *Auto Machine Learning*

Nesse pequeno projeto será usada a biblioteca *Pycaret* para modelagem de séries temporais de preços de ações. Aqui será usado o módulo de regressão dessa biblioteca e para isso iremos transformar a série temporal em um formato tabular; isso é necessário, pois modelos de regressão estimam a relação entre as variáveis explicativas ou independentes (*features*) com a variável dependente ou a ser explicada (*target*). O objetivo desses tipos de modelos é prever valores contínuos e o módulo de regressão da *Pycaret* permite que sejam realizados pré-processamento dos dados e a aplicação de cerca de 25 modelos de regressão.

## Instalação da biblioteca *Pycaret*
"""

pip install pycaret

"""## Importação das bibliotecas


"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pandas_datareader import data as wb

from pycaret.regression import *
from pycaret.utils import check_metric
from sklearn.metrics import r2_score, median_absolute_error, mean_squared_log_error, mean_squared_error, mean_absolute_error

"""## Importação dos dados

Aqui iremos usar a série de preços de fechamento da ação *BBDC4.SA*, extraídos do *Yahoo Finance*; essa ação é do banco Bradesco, um dos maiores bancos do Brasil. A série tem periodicidade diária e vai de 01 de Janeiro de 2019 até 01 de Junho de 2021, com 595 observações. Mais informações sobre essa ação podem ser acessadas [aqui](https://finance.yahoo.com/quote/BBDC4.SA/key-statistics?p=BBDC4.SA).

Abaixo uso a biblioteca *Pandas Data Reader* para a extração desses dados.
"""

tickers=['BBDC4.SA']
newdata=pd.DataFrame()
for t in tickers:
    newdata[t]=wb.DataReader(t,data_source='yahoo',start='2019-1-1',end='2021-06-01')['Adj Close']

"""Primeiras observações da série temporal."""

newdata.head()

"""Últimas observações da série."""

newdata.tail()

"""Não há valores faltantes na série."""

newdata.isna().sum()

"""Tabela estatística da série temporal."""

newdata.describe()

"""Dimensão da série."""

newdata.shape

"""Abaixo temos o gráfico da série."""

newdata.plot(figsize=(20,7))
plt.title('Série de tempo da BBCD4.SA', size=15)
plt.xlabel('Período', size=15);

"""## Conversão de série temporal

Como dito anteriormente é ncessário transformar a série em uma estrutura para serem usados os modelos de regressão, por isso é do nosso interesse que os dados estajam no formato supervisionado (variáveis explicativas e variável a ser explicada).

Para isso irei criar duas listas vazias.
"""

x_data = []
y_data = []

"""Formatando a série para que cada linha da base de dados *x_data* seja composta pelos 5 dias anteriores."""

for d in range(5,newdata.shape[0]):
    x = newdata.iloc[d-5:d].values.ravel()
    y = newdata.iloc[d].values[0]
    x_data.append(x)
    y_data.append(y)

"""Agora vamos transformar *X* e *y* em um único *dataset*."""

y = pd.DataFrame(y_data)
X = pd.DataFrame(x_data)
X['target']=y

"""Primeiras linhas da nova base de dados."""

X.head()

"""Últimas linhas."""

X.tail()

"""Dimensões da nova base de dados."""

X.shape

"""## Separando os dados de treino e teste

Aqui não usaremos o *train_test_split*, pois essa função aleatoriza os dados de treino e teste. Como é uma série temporal é necessário que a ordem dos dados seja mantida, por isso os dados para teste serão as 119 últimas observações e o que estiver antes, será para treino.
"""

x_treino = X[:-119]
x_teste = X[-119:]

"""## Modelagem de *Auto Machine Learning*

Passaremos para as configurações da função a base de treino, a variável alvo e a parte dos dados usada para treino, porém diferente do convencional usarei o parâmetro *fold_strategy* para séries temporais.
"""

reg1 = setup(data =x_treino, target = 'target', fold_strategy='timeseries' ,train_size = 0.8)

"""Usando os modelos : agora usarei todos os modelos possíveis e irei ordenar os melhores modelos pela métrica *MAE* (*Mean Absolute Error*), mas é possível usar outras métricas.

O melhor modelo foi o *Orthogonal Matching Pursuit	* que tem como código a sigla *omp*. Coincidentemente as outras métricas desse modelo apresentaram um melhor desempenho do que as dos outros modelos.
"""

best = compare_models(turbo=False, sort = 'MAE')

"""Abaixo temos a validação cruzada realizada pelo modelo."""

omp = create_model('omp')
print(omp)

"""Realizando o *Tunning* do modelo: realizamos automaticamente uma busca para que fossem encontrados outros parâmetros para melhorar o desempenho do modelo. O resultado mostra que houve uma ligeira piora em algumas métricas e de seus desvios-padrão.

Sendo assim, ficamos com o modelo anterior.
"""

tune_omp = tune_model(omp)
print(tune_omp)

"""Aqui vemos o desempenho do modelo sendo usado nos dados de treino e teste. Nos dados de treino a métrica de *R²* foi de 0.981 e o de teste 0.984; como os valores estão bem próximos podemos afastar a suspeita de *overfitting* e de *underfitting*. 

Os resíduos apresentam estar concentrados em torno de zero, então o modelo apresenta ter um bom desempenho.
"""

plot_model(omp)

"""Esse gráfico compara o modelo gerado (*best fit*) com um modelos ideal (*identity*), onde no eixo x estão os valores reais e no eixo y os valores preditos (no modelo ideal os valores preditos são idênticos aos valores reais). Como as retas estão praticamente coincidindo, temos uma evidência do bom desempenho do modelo. """

plot_model(omp, plot='error')

"""A distância de *Cook* é uma medida da influência de uma observação ou instâncias em uma regressão linear. Instâncias com grande influência podem ser *outliers*, e conjuntos de dados com um grande número de pontos altamente influentes podem não ser adequados para regressão linear sem processamento adicional, como remoção de *outlier* ou imputação. 

Os pontos destacados no gráfico são dados discrepantes e vemos que temos muito desses por volta das observações 290 a 300.
"""

plot_model(omp, plot='cooks')

"""Aqui vemos qual(is) a(s) variável(is) mais importante(s) para o nosso modelo, que foi a variável 4. Conforme o gráfico abaixo, a variável 4 tem, praticamente, 100% de importância para o modelo."""

plot_model(omp, plot='feature')

"""Curva de aprendizado do modelo."""

plot_model(omp, plot='vc')

"""Parâmetros do modelo."""

plot_model(omp, plot='parameter')

"""## Previsões com o modelo

Nessa última etapa serão geradas as previsões do modelo abaixo.
"""

predict_model(omp)

"""Abaixo pode-se ver graficamente os valores preditos e os valores reais.

Não há necessidade importar funções para avaliar os resultados, pois isso já é feito abaixo. 
"""

predict_model(omp)[['target','Label']].plot(color=['r','b'],figsize=(20,5));

"""## Finalizando o modelo

Agora o modelo será treinado com todos os dados de treino (retreino). Abaixo vemos o modelo retreinado com os parâmetros escolhidos pela biblioteca.
"""

final_omp=finalize_model(omp)
print(final_omp)

"""E podemos criar as previsões para esse modelo retreinado."""

predict_model(final_omp);

"""Agora podemos usar esse modelo para uma etapa de validação: temos dados de uma base que o modelo não teve contato e podemos usar para avaliar se o modelo gera boa previsões.

Temos abaixo o *dataset* de teste, mas com uma variável a mais (*Label*), que é o resultado da inserção das variáveis explicativas (0,1,2,3 e 4) no modelo que encontramos.
"""

predicoes = predict_model(final_omp, data=x_teste)
predicoes.head()

"""Abaixo temos um gráfico com os valores reais e preditos."""

predicoes['target'].plot(figsize=(20,5))
predicoes['Label'].plot()
plt.legend(['Valores reais','Valores preditos'], fontsize=15)
plt.xlabel('Períodos',size=15)
plt.title('Valores reais e preditos',size=15);
#x_treino['target'].plot();

"""## Avaliação do modelo

Vemos que o modelo não gerou as métricas, então podemos avaliar usando as métricas da biblioteca *SKlearn*.

Vemos abaixo que o coeficiente de determinação está abaixo de 90 (diferente dos resultados de antes), porém ainda sim é um bom resultado. As demais métricas de erros estão abaixo de 1, o que mostra que os resultados são satisfatórios.
"""

print('Coeficiente de determinação :',r2_score(predicoes['Label'],predicoes['target']))
print('Erro absoluto mediano :',median_absolute_error(predicoes['Label'],predicoes['target']))
print('Erro absoluto logatítmico médio :',mean_squared_log_error(predicoes['Label'],predicoes['target']))
print('Erro quadrado médio :',mean_squared_error(predicoes['Label'],predicoes['target']))
print('Erro absoluto mediano :',mean_absolute_error(predicoes['Label'],predicoes['target']))

"""## Conclusão

Vemos que a biblioteca *Pycaret* pode ser útil para modelagem de séries temporais, usando as defasagens da variável como regressores. Assim como outros projetos desenvolvidos, a grande vantagem dessa biblioteca é o tempo de pré-processamento dos dados que é muito menor do que realizar toda uma codificação e a escolha do modelo de forma mais automatizada.

Enquanto essa biblioteca ainda não tem um módulo exclusivo para séries temporais (expectativa para a implementação desse novo módulo é para Julho de 2021) isso se torna uma alternativa de modelagem e previsão.
"""